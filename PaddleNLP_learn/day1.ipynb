{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业\n",
    "\n",
    "更换TokenEmbedding预训练模型，使用VisualDL查看相应的TokenEmbedding可视化效果，并尝试更换后的TokenEmbedding计算句对语义相似度。\n",
    "本作业详细步骤，可参考[Day01作业教程](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/education/day01.md)，记得star PaddleNLP，收藏起来，随时跟进最新功能噢。\n",
    "\n",
    "**作业结果提交**：\n",
    "1. 截图提交可视化结果（图片注明作业可视化结果）。\n",
    "2. 通篇执行每段代码，并保留执行结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PaddleNLP词向量应用展示\n",
    "\n",
    "6.7日NLP直播打卡课开始啦\n",
    "\n",
    "**[直播链接请戳这里，每晚20:00-21:30👈](http://live.bilibili.com/21689802)**\n",
    "\n",
    "**[课程地址请戳这里👈](https://aistudio.baidu.com/aistudio/course/introduce/24177)**\n",
    "\n",
    "欢迎来课程**QQ群**（群号:618354318）交流吧~~\n",
    "\n",
    "\n",
    "词向量（Word embedding），即把词语表示成实数向量。“好”的词向量能体现词语直接的相近关系。词向量已经被证明可以提高NLP任务的性能，例如语法分析和情感分析。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/54878855b1df42f9ab50b280d76906b1e0175f280b0f4a2193a542c72634a9bf\" width=\"60%\" height=\"50%\"> <br />\n",
    "</p>\n",
    "<br><center>图1：词向量示意图</center></br>\n",
    "\n",
    "PaddleNLP已预置多个公开的预训练Embedding，您可以通过使用`paddlenlp.embeddings.TokenEmbedding`接口加载预训练Embedding，从而提升训练效果。本篇教程将依次介绍`paddlenlp.embeddings.TokenEmbedding`的初始化和文本表示效果，并通过文本分类训练的例子展示其对训练提升的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 加载TokenEmbedding\n",
    "\n",
    "`TokenEmbedding()`参数\n",
    "- `embedding_name`\n",
    "将模型名称以参数形式传入TokenEmbedding，加载对应的模型。默认为`w2v.baidu_encyclopedia.target.word-word.dim300`的词向量。\n",
    "- `unknown_token`\n",
    "未知token的表示，默认为[UNK]。\n",
    "- `unknown_token_vector`\n",
    "未知token的向量表示，默认生成和embedding维数一致，数值均值为0的正态分布向量。\n",
    "- `extended_vocab_path`\n",
    "扩展词汇列表文件路径，词表格式为一行一个词。如引入扩展词汇列表，trainable=True。\n",
    "- `trainable`\n",
    "Embedding层是否可被训练。True表示Embedding可以更新参数，False为不可更新。默认为True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389084/389084 [00:12<00:00, 32125.66it/s]\n",
      "[2021-06-09 09:48:48,907] [    INFO] - Loading token embedding...\n",
      "[2021-06-09 09:48:54,604] [    INFO] - Finish loading embedding vector.\n",
      "[2021-06-09 09:48:54,607] [    INFO] - Token Embedding info:             \n",
      "Unknown index: 356053             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 356054             \n",
      "Padding token: [PAD]             \n",
      "Shape :[356055, 300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object   type: TokenEmbedding(356055, 300, padding_idx=356054, sparse=False)             \n",
      "Unknown index: 356053             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 356054             \n",
      "Padding token: [PAD]             \n",
      "Parameter containing:\n",
      "Tensor(shape=[356055, 300], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [[ 0.26137900, -0.23154099,  0.20605899, ...,  0.30245501, -0.46408200,  0.12339000],\n",
      "        [-0.46408099,  0.06294300,  0.38740700, ...,  0.01816300,  0.25432301, -0.10378600],\n",
      "        [ 0.23366600,  0.20877300, -0.22048600, ...,  0.47785801, -0.64790398, -0.17877500],\n",
      "        ...,\n",
      "        [ 0.12553801,  0.02520600,  0.02330900, ...,  0.01679000, -0.18496101,  0.06710100],\n",
      "        [-0.00169146, -0.01700190, -0.03924349, ..., -0.00482547, -0.04594910,  0.00201318],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,  0.        ,  0.        ]])\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.embeddings import TokenEmbedding\n",
    "\n",
    "# 初始化TokenEmbedding， 预训练embedding未下载时会自动下载并加载数据\n",
    "# 需要更换所选的词向量\n",
    "token_embedding = TokenEmbedding(embedding_name=\"w2v.people_daily.target.bigram-char.dim300\")\n",
    "\n",
    "# 查看token_embedding详情\n",
    "print(token_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**首先查看一下可以用的tokenembedding有哪些**\n",
    "\n",
    "这里根据训练集，维度，语言，功能有很多区分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v.baidu_encyclopedia.target.word-word.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-character.char1-1.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-character.char1-2.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-character.char1-4.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-ngram.1-2.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-ngram.1-3.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-ngram.2-2.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-wordLR.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.word-wordPosition.dim300',\n",
       " 'w2v.baidu_encyclopedia.target.bigram-char.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-word.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-character.char1-1.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-character.char1-2.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-character.char1-4.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-ngram.1-2.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-ngram.1-3.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-ngram.2-2.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-wordLR.dim300',\n",
       " 'w2v.baidu_encyclopedia.context.word-wordPosition.dim300',\n",
       " 'w2v.wiki.target.bigram-char.dim300',\n",
       " 'w2v.wiki.target.word-char.dim300',\n",
       " 'w2v.wiki.target.word-word.dim300',\n",
       " 'w2v.wiki.target.word-bigram.dim300',\n",
       " 'w2v.people_daily.target.bigram-char.dim300',\n",
       " 'w2v.people_daily.target.word-char.dim300',\n",
       " 'w2v.people_daily.target.word-word.dim300',\n",
       " 'w2v.people_daily.target.word-bigram.dim300',\n",
       " 'w2v.weibo.target.bigram-char.dim300',\n",
       " 'w2v.weibo.target.word-char.dim300',\n",
       " 'w2v.weibo.target.word-word.dim300',\n",
       " 'w2v.weibo.target.word-bigram.dim300',\n",
       " 'w2v.sogou.target.bigram-char.dim300',\n",
       " 'w2v.sogou.target.word-char.dim300',\n",
       " 'w2v.sogou.target.word-word.dim300',\n",
       " 'w2v.sogou.target.word-bigram.dim300',\n",
       " 'w2v.zhihu.target.bigram-char.dim300',\n",
       " 'w2v.zhihu.target.word-char.dim300',\n",
       " 'w2v.zhihu.target.word-word.dim300',\n",
       " 'w2v.zhihu.target.word-bigram.dim300',\n",
       " 'w2v.financial.target.bigram-char.dim300',\n",
       " 'w2v.financial.target.word-char.dim300',\n",
       " 'w2v.financial.target.word-word.dim300',\n",
       " 'w2v.financial.target.word-bigram.dim300',\n",
       " 'w2v.literature.target.bigram-char.dim300',\n",
       " 'w2v.literature.target.word-char.dim300',\n",
       " 'w2v.literature.target.word-word.dim300',\n",
       " 'w2v.literature.target.word-bigram.dim300',\n",
       " 'w2v.sikuquanshu.target.word-word.dim300',\n",
       " 'w2v.sikuquanshu.target.word-bigram.dim300',\n",
       " 'w2v.mixed-large.target.word-char.dim300',\n",
       " 'w2v.mixed-large.target.word-word.dim300',\n",
       " 'w2v.google_news.target.word-word.dim300.en',\n",
       " 'glove.wiki2014-gigaword.target.word-word.dim50.en',\n",
       " 'glove.wiki2014-gigaword.target.word-word.dim100.en',\n",
       " 'glove.wiki2014-gigaword.target.word-word.dim200.en',\n",
       " 'glove.wiki2014-gigaword.target.word-word.dim300.en',\n",
       " 'glove.twitter.target.word-word.dim25.en',\n",
       " 'glove.twitter.target.word-word.dim50.en',\n",
       " 'glove.twitter.target.word-word.dim100.en',\n",
       " 'glove.twitter.target.word-word.dim200.en',\n",
       " 'fasttext.wiki-news.target.word-word.dim300.en',\n",
       " 'fasttext.crawl.target.word-word.dim300.en']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paddlenlp.embeddings import TokenEmbedding\r\n",
    "import paddlenlp\r\n",
    "paddlenlp.embeddings.list_embedding_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 认识一下Embedding\n",
    "**`TokenEmbedding.search()`**\n",
    "获得指定词汇的词向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.245299 -0.063509  0.213156 -0.429391  0.825422 -0.119011  0.02137\n",
      "   0.076543  0.085277  0.492101 -0.050074  0.035595  0.509381  0.179038\n",
      "   0.456816  0.108855  0.041408 -0.153931  0.129657 -0.565065 -0.335973\n",
      "  -0.515457  0.396934  0.96231  -0.265134  0.164116 -0.725352 -0.539651\n",
      "   0.760359 -0.151472  0.506642  0.635705  0.648893 -0.183843 -0.131642\n",
      "   0.649702  0.496052  0.159072 -0.06204  -0.512253 -0.295271  0.127087\n",
      "  -0.288607 -0.292584 -0.016321 -0.586327 -0.114622  0.00445  -0.068454\n",
      "  -0.230694  0.510607  0.191056 -0.35957   0.287977 -0.031446  0.468448\n",
      "  -0.016571 -0.764257 -0.014768 -0.600075  0.472969 -0.027864 -0.406401\n",
      "   0.575796  0.381489 -0.385134 -0.342893  0.127585 -0.649147  0.057982\n",
      "   0.379719  0.335534 -0.504159 -0.258878 -0.094977  0.002911  0.134969\n",
      "   0.804434 -0.657511 -0.011848  0.491697  0.186991 -0.310367 -0.203108\n",
      "  -0.284629 -0.065764 -0.19618   0.245264  0.813726 -0.534868  0.143717\n",
      "  -0.348675 -0.391534 -0.074511 -0.207123  0.833282 -0.147526  0.319367\n",
      "  -0.007548  0.148096  0.744889 -0.036795 -0.298785 -0.773522  0.507116\n",
      "   0.579431  0.015625  0.51639  -0.031662 -0.696218 -0.074225  0.039992\n",
      "  -0.635147 -0.163501  0.567359  0.083905  0.129552 -0.041143  0.407512\n",
      "   0.735241 -0.364662  0.063807 -0.207793  0.506748  0.44802   0.654328\n",
      "  -0.654384  0.035223  0.103692 -0.293683  0.001821  0.407118 -1.066368\n",
      "  -0.440998 -0.158601  0.020035 -0.058469  0.187611  0.496692  0.606644\n",
      "  -0.304762 -0.239783 -0.267076  0.319635  0.118853  0.834611  0.723382\n",
      "  -0.688042  0.487927 -0.069738  0.134901 -0.424433  0.612888 -0.104039\n",
      "  -0.159641 -0.692073 -0.071576  0.479014  0.083112 -0.187132  0.265853\n",
      "   0.54581   0.762061  0.276219  0.306605  0.913264  0.439047  0.224081\n",
      "  -0.188732 -0.304422  0.055622  0.193861 -0.202978  1.507041  0.247001\n",
      "   0.105551  0.185101 -0.08144  -0.105758  0.538837  0.551993  1.114562\n",
      "  -0.336673  0.372092 -0.248727  0.329764 -0.590782 -0.179493  0.1205\n",
      "   0.00415  -0.694753 -0.539717  0.026847  0.085574  0.176655  0.394371\n",
      "   0.605641 -0.315098  0.451017 -0.448997  0.162211  0.352712 -0.443274\n",
      "  -0.1301   -0.028048 -0.105846 -0.194112  0.233397 -0.676047  0.210812\n",
      "   0.324972  0.800476  0.150799 -0.050848  0.018519 -0.127538  0.247602\n",
      "  -0.565047 -1.291294 -0.110274 -0.367249 -0.035681 -0.00913  -0.307435\n",
      "  -0.444762  0.533835 -0.618415  0.162594  0.05615   0.330124 -0.050551\n",
      "  -0.066869  0.035072 -0.254207  0.127291 -0.675879  0.360288 -0.007439\n",
      "  -0.28487  -0.711029 -0.504446  0.523299  0.186541  0.143999 -0.06729\n",
      "  -0.069645 -0.020837 -0.616062  0.262552 -0.046329 -0.621772 -0.162099\n",
      "   0.461422  0.47362   0.314044 -0.161183 -0.154762 -0.589609  0.035129\n",
      "  -0.441733 -0.151377 -0.23749   0.442486  0.73507   0.547519 -0.724635\n",
      "   0.678552 -0.047829  0.577742  0.773639 -0.57989   0.274129  0.051853\n",
      "   0.121788 -0.448002 -0.631761 -0.14499   0.230851  0.24288  -0.282543\n",
      "   0.152128  0.901109  0.280652  0.105189 -0.898267 -0.165797  0.336449\n",
      "   0.206998 -0.295348  0.211649 -0.737738  0.436789 -0.388129 -0.152419\n",
      "   0.005798  0.369259  0.052433 -0.058367  0.361513 -0.012527]]\n"
     ]
    }
   ],
   "source": [
    "test_token_embedding = token_embedding.search(\"中国\")\n",
    "print(test_token_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**`TokenEmbedding.cosine_sim()`**\n",
    "计算词向量间余弦相似度，语义相近的词语余弦相似度更高，说明预训练好的词向量空间有很好的语义表示能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1: 0.61954707\n",
      "score2: 0.19051214\n"
     ]
    }
   ],
   "source": [
    "score1 = token_embedding.cosine_sim(\"女孩\", \"女人\")\n",
    "score2 = token_embedding.cosine_sim(\"女孩\", \"书籍\")\n",
    "print('score1:', score1)\n",
    "print('score2:', score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 词向量映射到低维空间\n",
    "\n",
    "使用深度学习可视化工具[VisualDL](https://github.com/PaddlePaddle/VisualDL)的[High Dimensional](https://github.com/PaddlePaddle/VisualDL/blob/develop/docs/components/README_CN.md#High-Dimensional--%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E7%BB%84%E4%BB%B6)组件可以对embedding结果进行可视化展示，便于对其直观分析，步骤如下：\n",
    "\n",
    "1. 升级 VisualDL 最新版本。\n",
    "\n",
    "`pip install --upgrade visualdl`\n",
    "\n",
    "2. 创建LogWriter并将记录词向量。\n",
    "\n",
    "3. 点击左侧面板中的可视化tab，选择‘token_hidi’作为文件并启动VisualDL可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade visualdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取词表中前2000个单词\n",
    "labels = token_embedding.vocab.to_tokens(list(range(0, 2000)))\n",
    "\n",
    "# 取出这2000个单词对应的Embedding\n",
    "test_token_embedding = token_embedding.search(labels)\n",
    "\n",
    "# 引入VisualDL的LogWriter记录日志\n",
    "from visualdl import LogWriter\n",
    "\n",
    "with LogWriter(logdir='./token_hidi') as writer:\n",
    "    writer.add_embeddings(tag='0-2000', mat=[i for i in test_token_embedding], metadata=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**效果如图：**\n",
    "\n",
    "**T-SNE降维方法的结果**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b153ffcb0d9f4164a84727ee192a026e6c77da1679604c68812913b07663d6d5)\n",
    "\n",
    "**UMAP方法的结果**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6ad823e5b4d844428df56a6196fac57081fceeddb52e49c7a22c6b687dddb3d6)\n",
    "\n",
    "**PCA方法的结果**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/83dc95ef8a9f4497ba46358b57ece92b62d9cb0088f34b55a5b0f24e1a5fdd53)\n",
    "\n",
    "\n",
    "可以看出来，UMAP的直观效果最好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "数据降维的过程中：\n",
    "\n",
    "这里顺便查了一下TSNE，PCA，UMAP算法的异同\n",
    "\n",
    "参考了一篇文章：\n",
    "\n",
    "[Dimensionality Reduction for Data Visualization: PCA vs TSNE vs UMAP](https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29)\n",
    "\n",
    "可以看原文的[机翻](http://www.weainfo.net/news/detail/453570)\n",
    "\n",
    "降维的两种主要方法：投影和流形学习。\n",
    "\n",
    "投影：这种技术处理将每个高维的数据点投影到子空间适合的低维空间上，从而近似地保持点之间的距离。\n",
    "\n",
    "流形学习：许多降维算法通过对训练实例所在的流形进行建模来工作；这称为流形学习。它依赖于流形假设或假设，它认为大多数真实世界的高维数据集都接近一个低维的流形，这种假设在大多数情况下是基于观察或经验，而不是理论或纯逻辑。\n",
    "\n",
    ">PCA主成分分析：\n",
    ">\n",
    ">The axis that explains the maximum amount of variance in the training set is called the Principal Components.\n",
    ">\n",
    ">The axis orthogonal to this axis is called the second principal component. As we go for higher dimensions, PCA would find a third component orthogonal to the other two components and so on, for visualization purposes we always stick to 2 or maximum 3 principal components.\n",
    ">\n",
    ">这段解释了什么是主成分以及过程：find a third component orthogonal to the other two components\n",
    ">\n",
    ">缺点：极值和非线性：The main drawback of PCA is that it is highly influenced by outliers present in the data. Moreover, PCA is a linear projection, which means it can’t capture non-linear dependencies.\n",
    "\n",
    ">t-SNE(T-distributed stochastic neighbour embedding)\n",
    ">\n",
    ">(t-SNE) takes a high dimensional data set and reduces it to a low dimensional graph that retains a lot of the original information. It does so by giving each data point a location in a two or three-dimensional map. This technique finds clusters in data thereby making sure that an embedding preserves the meaning in the data. t-SNE reduces dimensionality while trying to keep similar instances close and dissimilar instances apart.\n",
    ">\n",
    ">[详细解释](https://www.oreilly.com/content/an-illustrated-introduction-to-the-t-sne-algorithm/)\n",
    ">\n",
    ">原来的数据点$x_i,x_j$,映射的对应点$y_i,y_j$,$x$之间的距离：$p_{j|i} = \\frac{\\exp\\left(-\\left| x_i – x_j\\right|^2 \\big/ 2\\sigma_i^2\\right)}{\\displaystyle\\sum_{k \\neq i} \\exp\\left(-\\left| x_i – x_k\\right|^2 \\big/ 2\\sigma_i^2\\right)}$,得到相似矩阵$p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2N}$\n",
    ">\n",
    ">映射点的相似矩阵：$q_{ij} = \\frac{f(\\left| x_i – x_j\\right|)}{\\displaystyle\\sum_{k \\neq i} f(\\left| x_i – x_k\\right|)} \\quad \\textrm{with} \\quad f(z) = \\frac{1}{1+z^2}$\n",
    ">\n",
    ">这里有个物理意义的解释：Let’s assume that our map points are all connected with springs. The stiffness of a spring connecting points  and  depends on the mismatch between the similarity of the two data points and the similarity of the two map points, that is, . Now, we let the system evolve according to the laws of physics. If two map points are far apart while the data points are close, they are attracted together. If they are nearby while the data points are dissimilar, they are repelled.\n",
    ">\n",
    ">也就是说把这些点当作用弹簧连起来的，如果一侧距离近就会把另一侧带着拉近\n",
    ">\n",
    ">距离之间的KL散度：$KL(P||Q) = \\sum_{i, j} p_{ij} \\, \\log \\frac{p_{ij}}{q_{ij}}.$,求对$y_i$的偏导：$\\frac{\\partial \\, KL(P || Q)}{\\partial y_i} = 4 \\sum_j (p_{ij} – q_{ij}) g\\left( \\left| x_i – x_j\\right| \\right) u_{ij} \\quad \\textrm{where} \\, g(z) = \\frac{z}{1+z^2}.$,使用梯度下降法就能得到结果，VDL中也可以修改学习率\n",
    "\n",
    ">UMAP(Uniform Manifold Approximation and Projection)\n",
    ">\n",
    ">具有非线性，算力消耗比tsne少的特点\n",
    ">\n",
    ">算力消耗少的原因： 稀疏矩阵：it can be applied directly to sparse matrices thereby eliminating the need to applying any Dimensionality reduction such as PCA or Truncated SVD(Singular Value Decomposition) as a prior pre-processing step\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 基于TokenEmbedding衡量句子语义相似度\n",
    "\n",
    "在许多实际应用场景（如文档检索系统）中， 需要衡量两个句子的语义相似程度。此时我们可以使用词袋模型（Bag of Words，简称BoW）计算句子的语义向量。\n",
    "\n",
    "**首先**，将两个句子分别进行切词，并在TokenEmbedding中查找相应的单词词向量（word embdding）。\n",
    "\n",
    "**然后**，根据词袋模型，将句子的word embedding叠加作为句子向量（sentence embedding）。\n",
    "\n",
    "**最后**，计算两个句子向量的余弦相似度。\n",
    "\n",
    "### 基于TokenEmbedding的词袋模型\n",
    "\n",
    "\n",
    "使用`BoWEncoder`搭建一个BoW模型用于计算句子语义。\n",
    "\n",
    "* `paddlenlp.TokenEmbedding`组建word-embedding层\n",
    "* `paddlenlp.seq2vec.BoWEncoder`组建句子建模层\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddlenlp\n",
    "\n",
    "\n",
    "class BoWModel(nn.Layer):\n",
    "    def __init__(self, embedder):\n",
    "        super().__init__()\n",
    "        self.embedder = embedder\n",
    "        emb_dim = self.embedder.embedding_dim\n",
    "        self.encoder = paddlenlp.seq2vec.BoWEncoder(emb_dim)\n",
    "        self.cos_sim_func = nn.CosineSimilarity(axis=-1)\n",
    "\n",
    "    def get_cos_sim(self, text_a, text_b):\n",
    "        text_a_embedding = self.forward(text_a)\n",
    "        text_b_embedding = self.forward(text_b)\n",
    "        cos_sim = self.cos_sim_func(text_a_embedding, text_b_embedding)\n",
    "        return cos_sim\n",
    "\n",
    "    def forward(self, text):\n",
    "        # Shape: (batch_size, num_tokens, embedding_dim)\n",
    "        embedded_text = self.embedder(text)\n",
    "\n",
    "        # Shape: (batch_size, embedding_dim)\n",
    "        summed = self.encoder(embedded_text)\n",
    "\n",
    "        return summed\n",
    "\n",
    "model = BoWModel(embedder=token_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 构造Tokenizer\n",
    "使用TokenEmbedding词表构造Tokenizer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.set_vocab(vocab=token_embedding.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 相似句对数据读取\n",
    "\n",
    "以提供的样例数据text_pair.txt为例，该数据文件每行包含两个句子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_pairs = {}\n",
    "with open(\"text_pair.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        text_a, text_b = line.strip().split(\"\\t\")\n",
    "        if text_a not in text_pairs:\n",
    "            text_pairs[text_a] = []\n",
    "        text_pairs[text_a].append(text_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 查看相似语句相关度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 多项式矩阵的左共轭积及其应用\n",
      "cosine_sim: 0.8273115754127502\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 退化阻尼对高维可压缩欧拉方程组经典解的影响\n",
      "cosine_sim: 0.7478786110877991\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: Burgers方程基于特征正交分解方法的数值解法研究\n",
      "cosine_sim: 0.7302016019821167\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 有界对称域上解析函数空间的若干性质\n",
      "cosine_sim: 0.6930968165397644\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 基于卷积神经网络的图像复杂度研究与应用\n",
      "cosine_sim: 0.6603596806526184\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: Cartesian发射机中线性功率放大器的研究\n",
      "cosine_sim: 0.7091397643089294\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: CFRP加固WF型梁侧扭屈曲的几何非线性有限元分析\n",
      "cosine_sim: 0.7540827989578247\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 基于线性CCD自适应成像的光刻机平台调平方法研究\n",
      "cosine_sim: 0.7331011295318604\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 基于变分贝叶斯理论的图像复原方法研究\n",
      "cosine_sim: 0.7067816853523254\n",
      "\n",
      "text_a: 多项式矩阵左共轭积对偶Sylvester共轭和数学算子完备参数解\n",
      "text_b: 网格资源分配中混合并行蚁群算法方式研究\n",
      "cosine_sim: 0.6844235062599182\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 中心式停车信息系统若干问题的研究\n",
      "cosine_sim: 0.7012695670127869\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 视觉导航区域交通智能车辆（CyberCar）系统研究\n",
      "cosine_sim: 0.7435452938079834\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 需求侧参与输电阻塞管理的模型与算法研究\n",
      "cosine_sim: 0.7208659052848816\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 基于云服务的智能家居系统的研究与设计\n",
      "cosine_sim: 0.6938278079032898\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 环境水质在线监测系统智能主节点的研究与设计\n",
      "cosine_sim: 0.7543100118637085\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 配电网故障自动处理算法的研究及软件开发\n",
      "cosine_sim: 0.6975433826446533\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 基于GeoMedia的高速公路监控系统的研究与开发\n",
      "cosine_sim: 0.688828706741333\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 基于Java的模块化环境空气质量自动监测系统的研究与设计\n",
      "cosine_sim: 0.7014833092689514\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 边检预检预录系统建设及关键技术研究\n",
      "cosine_sim: 0.6752031445503235\n",
      "\n",
      "text_a: 停车信息系统路径诱导最佳路径车位占有率城市交通智能交通\n",
      "text_b: 基于多技术的路面积水监测预警系统的设计与实现\n",
      "cosine_sim: 0.7074209451675415\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 服务企业竞争力决定因素与提升策略研究\n",
      "cosine_sim: 0.958454430103302\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 提升我国分析仪器产业竞争力的技术创新战略研究\n",
      "cosine_sim: 0.7877742052078247\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 国有润滑油企业市场开发策略研究\n",
      "cosine_sim: 0.7734988927841187\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 基于成功要素的企业ERP实施事前评估研究\n",
      "cosine_sim: 0.7516673803329468\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 环境扫描对企业竞争优势的影响研究--以电子信息行业为例\n",
      "cosine_sim: 0.744232714176178\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 浦发银行信用卡产品的营销策略研究\n",
      "cosine_sim: 0.7184081077575684\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 我国出口企业的竞争战略研究\n",
      "cosine_sim: 0.7332179546356201\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: BMP公司供应商绩效指标体系的改进与实施\n",
      "cosine_sim: 0.7033064365386963\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: P公司企业管理人员选拔任用体系研究\n",
      "cosine_sim: 0.6867929697036743\n",
      "\n",
      "text_a: 服务企业企业竞争力决定因素提升策略\n",
      "text_b: 高管性别结构、内部制衡与企业技术创新——基于我国创业板上市企业的实证研究\n",
      "cosine_sim: 0.7298527956008911\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于混沌映射的数字水印技术研究\n",
      "cosine_sim: 0.8149649500846863\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于卷积神经网络的图像复杂度研究与应用\n",
      "cosine_sim: 0.6873020529747009\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于图像内容的关键帧检测及VLSI实现\n",
      "cosine_sim: 0.6949929594993591\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于局部特征的多光谱与全色图像融合算法研究\n",
      "cosine_sim: 0.739165723323822\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于嵌入式系统的人脸识别算法研究及其优化\n",
      "cosine_sim: 0.6771979928016663\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于多特征融合和图割模型的遥感影像云检测算法研究\n",
      "cosine_sim: 0.7142007350921631\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于动态符号执行的模糊测试方法研究\n",
      "cosine_sim: 0.6895363330841064\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于交通流增长特性的复杂网络演化建模研究\n",
      "cosine_sim: 0.6912761926651001\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 基于变分贝叶斯理论的图像复原方法研究\n",
      "cosine_sim: 0.7065275311470032\n",
      "\n",
      "text_a: 数字水印混沌映射版权保护序列密码小波变换\n",
      "text_b: 混沌控制和构造延迟混沌系统及应用的研究\n",
      "cosine_sim: 0.6731002926826477\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 汽车车架焊接结构强度和可靠性分析\n",
      "cosine_sim: 0.9051185846328735\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 基于天线传感器的FRP-钢结构典型损伤监测方法研究\n",
      "cosine_sim: 0.8074275851249695\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 有限元强度折减法对抗滑桩加固边坡的优化分析研究\n",
      "cosine_sim: 0.8088000416755676\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 弹性地基上周期梁板的隔振性能研究\n",
      "cosine_sim: 0.7433584332466125\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: SIGMA冷弯薄壁型钢构件畸变屈曲的理论研究\n",
      "cosine_sim: 0.768498420715332\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 梁拱组合刚构桥极限承载力分析与研究\n",
      "cosine_sim: 0.7568265199661255\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: CFRP加固WF型梁侧扭屈曲的几何非线性有限元分析\n",
      "cosine_sim: 0.7832686305046082\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 典型缺陷真型电容式玻璃钢套管电气特征参量测试实验研究\n",
      "cosine_sim: 0.7890298366546631\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 基于ABB机器人的结构光视觉引导焊缝跟踪技术的研究\n",
      "cosine_sim: 0.7367687821388245\n",
      "\n",
      "text_a: 有限元分析汽车车架焊缝危险部位寿命预测结构强度\n",
      "text_b: 紊流风场中大跨度桥梁非线性气动稳定性研究\n",
      "cosine_sim: 0.7676162719726562\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 石墨烯与导电聚合物复合材料的制备以及在超级电容器方面的应用\n",
      "cosine_sim: 0.8882289528846741\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 碳纤维布增强聚酰亚胺基复合材料的制备及其力学和摩擦学性能研究\n",
      "cosine_sim: 0.8038300275802612\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 石墨烯/硅橡胶复合材料的制备及压阻特性研究\n",
      "cosine_sim: 0.8749389052391052\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 功能化碳纳米管在染料敏化太阳能电池对电极中的应用\n",
      "cosine_sim: 0.8111415505409241\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 高介电常数铝阳极复合氧化膜制备技术的研究\n",
      "cosine_sim: 0.8643444776535034\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 导电生物可降解聚酯/CNT纤维在神经再生中的研究\n",
      "cosine_sim: 0.8217766284942627\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 二维MXene/镍基复合材料制备及其电化学性能研究\n",
      "cosine_sim: 0.8468989729881287\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: g--C3N4基复合材料的制备及其光催化性能研究\n",
      "cosine_sim: 0.7910307049751282\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 无溶剂厚膜型环氧涂料的制备及其防腐性能的研究\n",
      "cosine_sim: 0.7603501081466675\n",
      "\n",
      "text_a: 石墨烯导电聚合物复合材料超级电容器\n",
      "text_b: 并五苯分子的手性自组装和单层薄膜的结构相变\n",
      "cosine_sim: 0.669069230556488\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于多层结构的业务框架平台\n",
      "cosine_sim: 0.810208261013031\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于BPR的管理信息系统开发与应用\n",
      "cosine_sim: 0.7486777901649475\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于BIM的MEP管线综合知识库构建与可视化研究\n",
      "cosine_sim: 0.706699013710022\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于J2EE的网上书店电子商务应用框架的研究和设计\n",
      "cosine_sim: 0.6796621680259705\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于数字地球平台的中国世界遗产展示平台的设计与实现\n",
      "cosine_sim: 0.6390560269355774\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 面向组件技术的综合决策支持系统及其商业应用\n",
      "cosine_sim: 0.6916667819023132\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 在信息管理系统（MIS）平台上进行医学科研项目管理的应用研究\n",
      "cosine_sim: 0.7711800932884216\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于云服务的智能家居系统的研究与设计\n",
      "cosine_sim: 0.6557172536849976\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于PPP模式的W市政道路工程风险管理研究\n",
      "cosine_sim: 0.7591582536697388\n",
      "\n",
      "text_a: 企业管理管理信息系统多层结构框架平台\n",
      "text_b: 基于TD专网移动互联系统及应用的设计与实现\n",
      "cosine_sim: 0.6913069486618042\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 纳米CT三维图像处理分析方法及其应用的研究\n",
      "cosine_sim: 0.8316081762313843\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于线性CCD自适应成像的光刻机平台调平方法研究\n",
      "cosine_sim: 0.8330333232879639\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 固体中缺陷的超声散射计算与测量技术研究\n",
      "cosine_sim: 0.8324524164199829\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于多特征融合和图割模型的遥感影像云检测算法研究\n",
      "cosine_sim: 0.791139543056488\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于卷积神经网络的图像复杂度研究与应用\n",
      "cosine_sim: 0.736799418926239\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 微纳米结构非线性静动力学分析及其应用\n",
      "cosine_sim: 0.804399847984314\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于碳纳米管的流体器件设计\n",
      "cosine_sim: 0.8342471122741699\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于局部特征的多光谱与全色图像融合算法研究\n",
      "cosine_sim: 0.7986610531806946\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于嵌入式系统的人脸识别算法研究及其优化\n",
      "cosine_sim: 0.7690378427505493\n",
      "\n",
      "text_a: 纳米CT成像三维图像处理固体氧化物燃料电池多孔材料最优阈值算法边缘检测算法\n",
      "text_b: 基于TCAD的VDMOS功率器件仿真研究\n",
      "cosine_sim: 0.8157898783683777\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 在化学实验教学中培养高师学生的问题意识\n",
      "cosine_sim: 0.9143983125686646\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 职校计算机专业课有效教学的实践研究\n",
      "cosine_sim: 0.8368438482284546\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 新课程理念下的高中数学分层教学的实践与研究\n",
      "cosine_sim: 0.8208373188972473\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 信息技术课对提高中学生科学素养的准实验研究\n",
      "cosine_sim: 0.7777959704399109\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 形象思维理论指导高中物理教学实践的研究\n",
      "cosine_sim: 0.830427348613739\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 关于初中生数学归纳能力培养的理论与实践研究\n",
      "cosine_sim: 0.7685928344726562\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 分层教学在生物教学中的初步探索\n",
      "cosine_sim: 0.7785365581512451\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 课堂教学资源分配的社会学分析--以乌鲁木齐市民、汉学生同班的班级为例\n",
      "cosine_sim: 0.793648362159729\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 班级管理对学习动力影响的研究--中小学班级管理中班委会轮值制的效果分析研究\n",
      "cosine_sim: 0.7688800096511841\n",
      "\n",
      "text_a: 化学实验教学高师学生问题意识教学策略\n",
      "text_b: 目标设置在高三物理教学中应用的研究\n",
      "cosine_sim: 0.7984750270843506\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 互联网互动问答社区产品盈利模式选择研究\n",
      "cosine_sim: 0.9188004732131958\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 移动互联网时代下网易新闻客户端竞争战略研究\n",
      "cosine_sim: 0.7434406876564026\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 浦发银行信用卡产品的营销策略研究\n",
      "cosine_sim: 0.7891124486923218\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 当前我国电视娱乐节目品牌经营的策略研究\n",
      "cosine_sim: 0.7913224697113037\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 服务企业竞争力决定因素与提升策略研究\n",
      "cosine_sim: 0.7626203894615173\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 基于创新的中国广告产业演化研究\n",
      "cosine_sim: 0.7252452969551086\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 高管性别结构、内部制衡与企业技术创新——基于我国创业板上市企业的实证研究\n",
      "cosine_sim: 0.7685234546661377\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 环境扫描对企业竞争优势的影响研究--以电子信息行业为例\n",
      "cosine_sim: 0.7631784677505493\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 高管团队特征对公司绩效的影响——以我国新三板教育行业公司为例\n",
      "cosine_sim: 0.7213409543037415\n",
      "\n",
      "text_a: 互联网企业互动问答社区产品盈利模式经营策略商业价值\n",
      "text_b: 国有润滑油企业市场开发策略研究\n",
      "cosine_sim: 0.7791593670845032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_a, text_b_list in text_pairs.items():\n",
    "    text_a_ids = paddle.to_tensor([tokenizer.text_to_ids(text_a)])\n",
    "\n",
    "    for text_b in text_b_list:\n",
    "        text_b_ids = paddle.to_tensor([tokenizer.text_to_ids(text_b)])\n",
    "        print(\"text_a: {}\".format(text_a))\n",
    "        print(\"text_b: {}\".format(text_b))\n",
    "        print(\"cosine_sim: {}\".format(model.get_cos_sim(text_a_ids, text_b_ids).numpy()[0]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 使用VisualDL查看句子向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 引入VisualDL的LogWriter记录日志\n",
    "import numpy as np\n",
    "from visualdl import LogWriter    \n",
    "# 获取句子以及其对应的向量\n",
    "label_list = []\n",
    "embedding_list = []\n",
    "\n",
    "for text_a, text_b_list in text_pairs.items():\n",
    "    text_a_ids = paddle.to_tensor([tokenizer.text_to_ids(text_a)])\n",
    "    embedding_list.append(model(text_a_ids).flatten().numpy())\n",
    "    label_list.append(text_a)\n",
    "\n",
    "    for text_b in text_b_list:\n",
    "        text_b_ids = paddle.to_tensor([tokenizer.text_to_ids(text_b)])\n",
    "        embedding_list.append(model(text_b_ids).flatten().numpy())\n",
    "        label_list.append(text_b)\n",
    "\n",
    "\n",
    "with LogWriter(logdir='./sentence_hidi') as writer:\n",
    "    writer.add_embeddings(tag='句子', mat=embedding_list, metadata=label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**T-SNE效果**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6d5cbc4df14d4327ab6eb6c7b38e55ce88bbd044f7ed42b3a81bded810df788a)\n",
    "\n",
    "**UMAP效果**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8194b0dcb1aa4f25a8b46989da3c2c0640ec269ea5754048b3599ff51d512596)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PaddleNLP更多预训练词向量\n",
    "PaddleNLP提供61种可直接加载的预训练词向量，训练自多领域中英文语料、如百度百科、新闻语料、微博等，覆盖多种经典词向量模型（word2vec、glove、fastText）、涵盖不同维度、不同语料库大小，详见[PaddleNLP Embedding API](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/model_zoo/embeddings.md)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 预训练词向量辅助分类任务\n",
    "\n",
    "想学习词向量更多应用，来试试预训练词向量对分类模型的改善效果吧，[这里](https://aistudio.baidu.com/aistudio/projectdetail/1283423) 试试把`paddle.nn.Embedding`换成刚刚学到的预训练词向量吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入课程交流群，一起学习吧\n",
    "\n",
    "现在就加入课程群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394\" width=\"200\" height=\"250\" >\n",
    "\n",
    "\n",
    "\n",
    "**[直播链接请戳这里，每晚20:00-21:30👈](http://live.bilibili.com/21689802)**\n",
    "\n",
    "**[还没有报名课程？赶紧戳这里，课程、作业安排统统在课程区哦👉🏻](https://aistudio.baidu.com/aistudio/course/introduce/24177)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
